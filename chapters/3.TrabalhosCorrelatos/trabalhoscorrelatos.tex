\chapter{Trabalhos Correlatos}
\label{cap:trabalhos_correlatos}

Neste capítulo serão analisados alguns projetos que focam rastreamento, identificação e localização de pessoas em um ambiente inteligente. Embora alguns dos projetos estudados utilizem abordagens multimodais, abordagens que usam mais de um tipo de dado de entrada como dados audiovisuais, este trabalho tem como foco identificação, localização e rastreamento monomodais baseados somente na utilização de imagens.

% Neste capítulo serão analisados alguns projetos que focam no rastreamento, identificação e localização de pessoas. Alguns dos projetos estudados utilizam técnicas de identificação e rastreamento multimodais. Técnicas multimodais são técnicas que usam mais de um tipo diferente de dado de entrada, como por exemplo técnicas que utilizam dados audiovisuais.

% Mesmo assim, somente as técnicas de identificação, localização e rastreamento monomodais que utilizarem imagens (cor, intensidade ou profundidade) como entrada serão descritas e analisadas.


A seguir é apresentada uma descrição dos projetos analisados que focam em soluções para rastreamento, localização e identificação dos usuários em um ambiente inteligente utilizando abordagens baseadas em imagens.

% Dentre os projetos estudados, destacam-se os seguintes projetos a seguir que focam em soluções para rastreamento, identificação e localização de usuários em um ambiente inteligente repleto de sensores.



\section{Projeto CHIL}

O Projeto CHIL (\textit{Computers in the Human Interaction Loop})~\cite{chil, computerschil} envolve uma rede de quinze laboratórios internacionais de pesquisa acadêmica e industrial. Eles colaboram entre si conduzindo pesquisas que tem por objetivo auxiliar a pessoas de forma proativa durante suas atividades diárias no ambiente de trabalho. Em especial, o projeto foca no desenvolvimento de sistemas que auxiliam as interações entre grupos de pessoas como, por exemplo, sistemas que facilitam a colaboração em reuniões e em salas de palestras. Dentre os protótipos que foram desenvolvidos no projeto destacam-se um ambiente de trabalho perceptivo e colaborativo e um sistema perceptivo de apoio a um escritório virtual.

Este projeto utiliza informações obtidas de diferentes algoritmos monomodais para criar um sistema de rastreamento e identificação multimodal a partir de dados audiovisuais das pessoas no ambiente. Apesar do foco desta monografia ser identificação, rastreamento e localização utilizando imagens, vale salientar que o Projeto CHIL representa uma das primeiras tentativas de realizar e avaliar sistematicamente rastreamento acústico com uma rede distribuída de microfones. Os relatos a seguir se concentram somente nas investigações que utilizam dados visuais (imagens) para rastreamento e identificação. 
% Referente a localização das pessoas no ambiente, o projeto focou somente na localização das pessoas que ``falam''~\cite{speaker-localization}.

\subsection{Rastreamento de pessoas}

As pesquisas sobre rastreamento no âmbito do Projeto CHIL concentraram-se principalmente no rastreamento de pessoas dentro de um ambiente inteligente. Neste contexto, o rastreamento tem o objetivo de determinar,  de maneira contínua, as coordenadas dos ocupantes na imagem capturada.

Os sensores utilizados no ambiente inteligente do Projeto CHIL incluem:	
	\begin{itemize}
		\item um mínimo de quatro câmeras fixas instaladas nos cantos do ambiente, com campos de visão sobrepostos;
		\item uma câmera com grande ângulo de visão fixa com vista para o ambiente inteiro;
		\item três arrays de microfones em forma de T de 4 canais cada;
		\item um microfone de Mark III de 64 canais.
	\end{itemize}

Esperava-se que essa grande quantidade de sensores disponíveis fosse uma vantagem, tendo em vista a alta redundância nas informações capturadas e boa cobertura do ambiente minimizando assim problemas como oclusão. Entretanto, foi relatado que tal redundância se tornou um grande desafio, pois surgiram problemas relativos à sincronização dos dados, transferência de processamento distribuído, fusão de espaço-temporal, entre outros.

Inicialmente, os sistemas do Projeto CHIL eram de uma única modalidade com inicialização manual, utilizando recursos simples e rastreamento de no máximo uma pessoa. Estes sistemas evoluíram para um sistema totalmente automático, com auto-inicialização, em tempo real, utilizando uma combinação de recursos capaz de rastrear alvos múltiplos.

Sobre os algoritmos de rastreamento visual, duas abordagens principais foram seguidas pelos vários sistemas de rastreamento desenvolvidos no Projeto CHIL:

	\begin{enumerate}
		\item Abordagem baseada em modelos, em que a redundância entre as câmeras são exploradas matendo um modelo 3D da pessoa rastreada e renderizando-o nos pontos de vista das câmeras. Os dados obtidos de cada câmera são utilizados para atualizar os parâmetros do modelo 3D a cada imagem~\cite{chilref1,chilref2,chilref3}. 
		\item Abordagem orientada a dados, onde sistemas de rastreamento 2D operam de forma independente sobre os diferentes ângulos de visão das câmeras e os dados do rastreamento pertencentes a um mesmo alvo são coletados no formato de um rastreamento 3D~\cite{chilref4,chilref5}. A elegância desta abordagem reside na sua capacidade inerente de lidar com os problemas encontrados por várias técnicas de rastreamento 2D como, por exemplo, oclusão.
	\end{enumerate}	

 Em termos de desempenho, foi observado que a abordagem baseada em modelos (1) geralmente prevê uma melhor acurácia, porém menos precisão do que a abordagem orientada a dados (2). Por outro lado, o tratamento das oclusões e da associação dos dados dos sistemas de rastreamentos independentes são as desvantagens do modelo orientado a dados. Foi identificado, no Projeto CHIL, que rastrear rostos ao invés de corpos inteiros diminui o impacto desses problemas.

 Também foi observado que a abordagem baseada em modelos facilita a incorporação de diversos tipos de recursos, como segmentos de primeiro plano, histogramas de cor, etc., que aumentam a robustez do rastreamento. Contudo, as dificuldades encontradas nesta abordagem se concentram na inicialização automática e na atualização dos modelos das pessoas.

 Os testes do sistema de rastreamento desenvolvido no Projeto CHIL foram feitos utilizando os dados dos seminários e reuniões do próprio projeto.

% As abordagens de rastreamento por meio de áudio e vídeo foram combinas em um rastreamento multimodal. Esse rastreamento multimodal é, notavelmente, baseado em filtro de partículas uma vez que permitem uma integração flexível de recursos através dos sensores~\cite{chil}.

% No rastreamento multimodal, era esperado que a fusão dos diferentes tipos de dados proveria resultados mais precisos, eliminando, assim, os efeitos de decisões erradas tomadas por algum rastreamento monomodal. Porém, não aconteceu o que se esperava. O rastreamento multimodal é altamente dependente das tarefas e dados em mãos, e exige um cuidadoso equilíbrio na disponibilidade e qualidade dos dados~\cite{chil}.

\subsection{Identificação de pessoas}


A fim de realizar a identificação de pessoas de forma natural e implícita em um ambiente inteligente, sensores distribuídos no ambiente devem monitorar continuamente o espaço de modo que o sistema de identificação opere em segundo plano sem necessitar de atenção e cooperação dos usuários.

Para a identificação de pessoas, o Projeto CHIL elegeu o reconhecimento facial, tendo em vista que a face é uma característica biométrica que permite uma identificação de forma natural e implícita. 

% A equipe do Projeto CHIL desenvolveu sistemas de reconhecimento facial tendo em vista que a face é uma característica biométrica que permite uma identificação de forma natural e implícita, conforme mencionado na Seção~\ref{sec:biometria}. 

Na tentativa de realizar o reconhecimento facial das pessoas presentes no ambiente inteligente, vários desafios foram encontrados no Projeto CHIL, como: grande variação da iluminação, sensores com baixa resolução, oclusão visual. Além disso dependendo da localização e distância dos sensores da pessoa a ser identificada os dados recebidos podem variar. Foi observado, também, que o fato das pessoas possuírem diferentes expressões faciais, diferentes cortes de cabelo, maquiagem, entre outros, dificultava ainda mais a tarefa. Entretanto, apesar de todos esses desafios, foi notado que o reconhecimento facial podia ser realizado de forma robusta utilizando múltiplos sensores no ambiente.

O sistema de identificação do Projeto CHIL utiliza sequências de imagens fornecidas pelas várias câmeras no ambiente inteligente. A cada $\displaysyle 200ms$ imagens das caixas delimitadoras das faces \footnote{Caixas delimitadoras são uma maneira de apontar a localização da face na imagem por meio de um enquadramento.} e posições dos centros dos olhos são extraídas. O canto inferior direito da Figura~\ref{chilImage} exemplifica a imagem da face extraída de uma pessoa no ambiente.

As faces extraídas são, então, alinhadas utilizando os centros dos olhos ou as caixas delimitadoras. Para obter robustez e minimizar erros, o sistema gera algumas imagens adicionais modificando as posições dos rótulos do centro dos olhos ou os rótulos das caixas delimitadoras das faces alterando, então, o alinhamento das faces nas imagens.

	\begin{figure}[hbt]
		\begin{center}
			\includegraphics[scale=0.4]{figuras/3.TrabalhosCorrelatos/chil.png}
		\end{center}
		\caption{Caixa delimitadora e posição do centro dos olhos no sistema de identificação facial do Projeto CHIL~\cite{chil}.}
		\label{chilImage}
	\end{figure}


No Projeto CHIL testou-se diferentes abordagens para reconhecimento facial. Uma delas realiza reconhecimento baseado em aparência utilizando transformada discreta de cosseno (DCT - \textit{Discrete Cosine Transform})~\cite{chilref6, chilref7}. Abordagens baseadas em PCA (\textit{Principal Component Analisys}) também foram testadas, baseadas em uma versão modificada da distância euclidiana com pesos~\cite{chilref8, chilref9} como medida da distância entre imagens. Foi testado também uma abordagem baseada em análise discriminante linear (LDA - \textit{Linear Discrimant Analysis}), porém sem sucesso pois as imagens das faces obtidas não eram linearmente separáveis~\cite{chilref8, chilref9}. 

Todas as abordagens testadas utilizam um classificador do ``vizinho'' mais próximo. As decisões obtidas dos vários pontos de vista das várias câmeras utilizando tal classificador são, então, combinados por meio de uma regra de soma ponderada~\cite{chilref8, chilref9}.

Experimentos realizados no projeto, utilizando os mesmos métodos para extração da face e normalização, mostraram que a abordagem baseada em aparência utilizando DCT apresentou os melhores resultados. Além disso, foi observado que selecionando somente as imagens frontais de faces, ao invés de todas as amostras disponíveis, como imagens de perfil, reduz a performance do sistema de reconhecimento. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{SmartFlow}

Em~\cite{salah} temos uma proposta de implementação de um sistema multimodal que realiza detecção de movimento, rastreamento de pessoas, reconhecimento facial, identificação baseado em características, localização baseada em áudio e módulos de identificação baseado em áudio no middleware \textit{SmartFlow}. Este último consiste em um middleware genérico cliente-servidor que da suporte para o processamento dos streams de dados. Ele permite transporte de grande quantidade de dados de sensores para algoritmos de reconhecimento em nós distribuídos na rede.

O sistema proposto realiza a fusão de todas as informações utilizando filtro de partículas para obter um sistema robusto de identificação e localização. Além disso, ele foi projetado para operar de uma maneira completamente automática, ou seja, sem intervenção do usuário.

% Salah et al~\cite{salah} propõe um sistema que realiza detecção de movimento, rastreamento de pessoas, reconhecimento facial, identificação baseado em características, localização baseada em áudio e módulos de identificação baseado em áudio. Além disso, o trabalho realiza a fusão de todas essas informações utilizando filtro de partículas para obter um sistema robusto de identificação e localização. O sistema foi projetado para operar de uma maneira completamente automática, ou seja, sem intervenção do usuário.

% Os \textit{streams} de dados são processados com ajuda de um \textit{middleware} genérico cliente-servidor chamado \textit{SmartFlow}, resultando em uma arquitetura portável para diferentes plataformas. Este \textit{middleware} permite transporte de grande quantidade de dados de sensores para algoritmos de reconhecimento em nós distribuídos na rede.

O projeto utiliza diferentes métodos para prover serviços de reconhecimento e rastreamento multimodal no ambiente inteligente. A Figura \ref{workflow} mostra o fluxo das informações no sistema multimodal: a identificação e localização multimodal utiliza informações de identificação e localização por meio de áudio e informações de identificação e rastreamento utilizando imagens. O objetivo do sistema é identificar cada usuário ao entrar pela porta e rastreá-lo no ambiente. 

	\begin{figure}[hbt]
		\begin{center}
			\includegraphics[scale=0.5]{figuras/3.TrabalhosCorrelatos/workflow.png}
		\end{center}
		\caption{Fluxo da informação na arquitetura do ambiente inteligente~\cite{salah}.}
		\label{workflow}
	\end{figure}

Os sensores utilizados e as condições do ambiente inteligente são (Figura \ref{upc}):

	\begin{itemize}
		\item quatro câmeras nos cantos da sala (rotuladas como Cam1 a Cam4 na Figura \ref{upc});
		\item uma câmera \textit{zenithal fish-eye} no telhado (rotulada como Cam8 na Figura \ref{upc});
		\item uma câmera ativa apontada e com zoom para a porta de entrada para capturar as faces das pessoas que entram na sala (rotulada como PTZ na Figura \ref{upc});
		\item um \textit{array} de microfones NIST Mark III de 64 canais ;
		\item três \textit{clusters} de microfone de 4 canais no formato de T;
		\item oito microfones no teto.
	\end{itemize}

	\begin{figure}[hbt]
		\begin{center}
			\includegraphics[scale=0.4]{figuras/3.TrabalhosCorrelatos/upc.png}
		\end{center}
		\caption{A configuração do ambiente inteligente~\cite{salah}.}
		\label{upc}
	\end{figure}


A seguir serão descritas a detecção de movimento, rastreamento, detecção e reconhecimento facial desse projeto que são realizados sobre as imagens coletadas pelas as câmeras no ambiente. Embora o sistema do projeto também realize a localização dos usuários no ambiente, a técnica utiliza amostras de áudio como dados de entrada que esta fora do escopo deste trabalho.

\subsection{Detecção de Movimento e Rastreamento}

A detecção de movimento implementada tenta separar o ``primeiro plano'' do ``fundo''. O método que o projeto utiliza é baseado na detecção de objetos em movimento sob a suposição que imagens em uma cena sem objetos em movimento mostra regularidades, que podem ser modeladas utilizando métodos estáticos. O conjunto de treinamento é construído por sequências pequenas de gravações \textit{offline} feitas da sala vazia.

Para realizar o rastreamento foi utilizado a abordagem de um mapa de ocupação probabilística (POM - \textit{probabilistic occupancy map})~\cite{pom} simplificado para ambientes internos, onde as trajetórias de movimentos são curtas e menos frequentes quando comparadas com trajetórias em ambientes externos. Somente as quatro câmeras nos cantos do ambiente são utilizadas.

Nesta abordagem, o mapa de ocupação é utilizado para projetar a imagem de um esboço de uma pessoa (um retângulo simples) em cada visão das câmeras.  As sobreposições entre os esboços e as detecções de movimento na imagem entre as várias câmeras indicam a presença de uma pessoa. A Figura~\ref{fig:pom} ilustra a distribuição da probabilidade de ocupação produzida pela solução implementada.

\begin{figure}[hbt]
		\begin{center}
			\includegraphics[scale=0.5]{figuras/3.TrabalhosCorrelatos/pom.png}
		\end{center}
		\caption{Mapa de ocupação probabilística. Adaptada de~\cite{salah}.}
		\label{fig:pom}
	\end{figure}

\subsection{Detecção e Reconhecimento Facial}

A detecção de face implementada no projeto utiliza o método \textit{Viola-Jones} e a biblioteca \textit{OpenCV}~\cite{opencv_library} (\textit{Open Source Computer Vision}). Somente a câmera que está apontada para a porta é utilizada, pois esta é a única que fornece imagens na qualidade necessária. As demais, fornecem imagens em baixa resolução.  

O módulo de detecção detecta somente faces frontais, em que os dois olhos, o nariz e a boca são visíveis. O resultado da detecção de face é uma imagem contendo uma caixa delimitadora da face detectada.

O reconhecimento facial no ambiente inteligente utiliza uma técnica que aproveita a vantagem do ambiente ser constantemente monitorado e combina a informação de várias imagens. Para cada sequência de imagens, as faces de um mesmo indivíduo são agrupadas. Então, para cada grupo, o sistema compara as imagens com uma galeria de imagens. Para cada grupo de imagens, as decisões individuais são combinadas em uma decisão única para o grupo.

Uma abordagem baseada em PCA (\textit{Principal Component Analisys}) foi utilizada para comparação entre as imagens, pois possui uma baixa complexidade computacional necessária para aplicações em tempo real~\cite{salah}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{AVIARY e MICASA}

% Esse projeto~\cite{trivedi} foi apelidado de Projeto DIVA pois nele foi desenvolvido uma nova arquitetura para ambientes inteligentes chamado DIVA. 
% Trivedi et al~\cite{trivedi} apresenta detalhes de um projeto de pesquisa de longo prazo, onde ambientes inteligentes com funcionalidades úteis são projetados, construídos e avaliados sistematicamente. Neste projeto foi desenvolvido uma nova arquitetura para ambientes inteligentes chamado DIVA. Esta nova arquitetura pode ser vista como uma rede inteligente de câmeras, que são controladas para prover diversas funcionalidades, tais como, detecção de intrusos, rastreamento de várias pessoas, pose do corpo e análise de postura, identificação de pessoas, modelagem do corpo humano e análise do movimento.

O laboratório de pesquisa CVRR (\textit{Computer Vision and Robotics Research}) da Universidade da Califórnia conta com dois ambientes inteligentes: o AVIARY e MICASA. Estes ambientes inteligentes são separados fisicamente, porém conectados. O primeiro (AVIARY) foi projetado para ser uma pequena sala de conferências. O segundo (MICASA) foi projetado para ser uma pequena sala de aula. A Figura~\ref{micasa_aviary} ilustra os dois ambientes e a disposição dos sensores neles utilizados. Em~\cite{trivedi} foi desenvolvido uma nova arquitetura para ambientes inteligentes chamado DIVA. Esta nova arquitetura pode ser vista como uma rede inteligente de câmeras, que são controladas para prover diversas funcionalidades, tais como, detecção de intrusos, rastreamento de várias pessoas, pose do corpo e análise de postura, identificação de pessoas, modelagem do corpo humano e análise do movimento.

\begin{figure}[hbt]
		\begin{center}
	\includegraphics[scale=0.5]{figuras/3.TrabalhosCorrelatos/micasa_aviary.png}
		\end{center}
		\caption{Representação dos ambientes inteligentes MICASA e AVIARY~\cite{trivedi}.}
		\label{micasa_aviary}
	\end{figure}

O sistema proposto por este projeto monitora o ambiente em baixa resolução de forma contínua, detectando somente a presença e suas dimensões. Formas de aquisição de imagens mais detalhadas são ativadas quando um evento ou atividade de potencial interesse é detectado. Esses eventos são os focos de atenção do sistema.

O monitoramento de baixa resolução e de grande área do ambiente é alcançado graças a algumas câmeras de amplo ângulo de visão e estáticas. Com um pequeno número de câmeras PTZ (\textit{pan/tilt/zoom}) ativas, múltiplos focos de atenção podem ser mantidos de forma simultânea.

Os sensores no ambiente inteligente AVIARY incluem:

	\begin{itemize}
		\item uma rede de quatro câmeras omnidirecionais;
		\item quatro câmeras PTZ;
		\item quatro câmeras retilíneas estáticas;
		\item dois \textit{arrays} de microfones com quatro microfones cada.
	\end{itemize}

As quatro câmeras omnidirecionais (ODVSs - \textit{Omni-Directional Vision Sensors}) estão perto dos cantos de uma mesa de reunião, cobrindo a sala inteira de dentro para fora, como mostrado na Figura \ref{micasa_aviary}. As câmeras PTZ e retilíneas estão nos ``vértices'' da sala a $\displaysytle 1.4m$ acima do chão. Os dois \textit{arrays} de microfones foram instalados na parede e no teto.

% Um computador é alocado para rastreamento, utilizando imagens das quatro câmeras omnidirecionais ou imagens das quatro câmeras retilíneas estáticas. Outro computador é utilizado para analisar os eventos de áudio e de vídeo. Um terceiro computador é utilizado para arquivar \textit{streams} de áudio e vídeo para posterior recuperação.

O ambiente inteligente MICASA é duas vezes maior que o AVIARY. Os sensores utilizados são:
	
	\begin{itemize}
		\item uma rede de quatro câmeras omnidirecionais;
		\item quatro câmeras PTZ;
		\item oito câmeras retilíneas estáticas.
	\end{itemize}

As câmeras omnidirecionais são instaladas no teto, como mostrado na Figura \ref{micasa_aviary}. As câmeras PTZ e quatro câmeras retilíneas foram instaladas de maneira similar ao ambiente AVIARY. As quatro câmeras retilíneas restantes foram instaladas nas paredes como mostrado como mostrado na Figura \ref{micasa_aviary}. As câmeras nos vértices possuem maior campo de visão para cobrir toda a sala e fazem parte do array de câmeras para rastreamento.

\subsection{Rastreamento e Reconhecimento facial}
 
Neste projeto foi desenvolvido um sistema em tempo-real que utiliza a rede de câmeras omnidirecionais e é responsável pelo rastreamento e reconhecimento facial. 

O rastreamento é feito utilizando subtração do fundo com remoção de sombras para detectar as silhuetas dos novos usuários no ambiente.  Com isso, essas silhuetas são rastreadas imagem por imagem.

Os resultados do rastreamento são utilizados para controlar o reconhecimento facial. As imagens obtidas do rastreamento são processadas utilizando um método de segmentação de tom de pele e são recortadas para obter as imagens com possíveis faces. 

Essas imagens, então, são classificadas para rejeitar as imagens sem faces. Para essa classificação é utilizado o método \textit{Eigenfaces}. Este último também é utilizado para realizar o reconhecimento facial utilizando a classificação do ``vizinho'' mais próximo.

O treinamento do algoritmo \textit{Eigenfaces} implementado é feito utilizando um banco com $\displaystyle 200$ imagens de faces de várias pessoas diferentes.

	\begin{figure}[hbt]
		\begin{center}
			\includegraphics[scale=0.8]{figuras/3.TrabalhosCorrelatos/facerec.png}
		\end{center}
		\caption{Método de detecção e reconhecimento facial~\cite{trivedi}.}
		\label{facerec}
	\end{figure}

\section{Comparativo}

Observando os projetos apresentados podemos listar um conjunto de características que valem a pena serem observadas em cada um. Cada projeto aborda a questão da obtenção de informações de contexto dos usuários com abordagens distintas, porém todos com o foco em aumentar o entendimento das aplicações sobre o contexto do ambiente. Dentre as características de cada projeto, destacam-se algumas mostradas na Tabela~\ref{tab:trab-correlatos}.

	\begin{table}[h]
		\begin{center}
			\caption{Algumas características do trabalhos analisados.}
			\label{tab:trab-correlatos}
			\begin{tabular}{c|l}
				\hline \bf Trabalhos Correlatos & \bf Características \\
				\hline 						  & 1. Protótipo de um ambiente de trabalho perceptivo\\
														& e colaborativo. \\
				  		 Projeto CHIL & 2. Protótipo de um sistema perceptivo de apoio a um\\
				  									& escritório virtual. \\
				  									& 3. Rastreamento multimodal. \\
				  									& 4. Identificação por meio de reconhecimento facial. \\
															
				\hline  				 & 1. Middleware SmartFlow.\\
												 & 2. Identificação por meio de reconhecimento facial.\\
							SmartFlow	 & 3. Rastreamento utilizando imagens.\\
												 & 4. Localização baseada em áudio. \\
												 & 5. Identifica as pessoas no momento em que entram no\\
												 & ambiente.\\

				\hline  							 & 1. Arquitetura para ambientes inteligentes DIVA.\\
															 & 2. Rastreamento utilizando imagens.\\
															 & 3. Detecção de Intrusos.\\
							 AVIARY e MICASA & 4. Identificação por meio de reconhecimento facial.\\
															 & 5. Monitora o ambiente em baixa resolução de forma \\
															 & contínua. Formas de aquisição de imagens mais detalhadas\\
															 & são ativadas quando um evento ou atividade de potencial \\
															 & interesse é detectado. \\
				\hline
			\end{tabular}
		\end{center}
	\end{table}

% Observando os projetos apresentados podemos listar um conjunto de caracter ́ıs- ticas que valem ser observadas neste trabalho. Cada projeto aborda a quest ̃ao do desenvolvimento na ubicomp com objetivos distintos, por ́em todos com o foco em facilitar o acesso a estas aplica ̧co ̃es aos recursos do ambiente. Dentre estas abordagens vemos a aplica ̧ca ̃o de middlewares ja ́ existentes em novas arquite- turas bem como o desenvolvimento de novos e a elaborac ̧ ̃ao de protocolos para a comunica ̧ca ̃o no smart space. Dentre as diversas caracter ́ısticas de cada projeto vamos analisar apenas quatro aspectos distintos: a forma como o projeto modela seu ambiente, quais plataformas sa ̃o almejadas pelo projeto, qual o arquitetura seguida pelos dispositivos e como estes se comunicam entre si.





















